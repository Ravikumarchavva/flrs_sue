target_column,output,flag,username,timestamp
churn,,,,2025-01-17 23:48:43.672190
churn,,,,2025-01-17 23:50:48.130970
Churn,"{""Training Progress"": ""100%"", ""Best Model"": ""GaussianNB(priors=None, var_smoothing=1e-09)"", ""Comparison Table"": ""<table class=\""dataframe table table-striped\"">\n  <thead>\n    <tr style=\""text-align: right;\"">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>Recall</th>\n      <th>Prec.</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>MCC</th>\n      <th>TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>nb</th>\n      <td>Naive Bayes</td>\n      <td>0.8000</td>\n      <td>0.8583</td>\n      <td>0.8667</td>\n      <td>0.8050</td>\n      <td>0.8185</td>\n      <td>0.5980</td>\n      <td>0.6286</td>\n      <td>0.008</td>\n    </tr>\n    <tr>\n      <th>lr</th>\n      <td>Logistic Regression</td>\n      <td>0.7857</td>\n      <td>0.8500</td>\n      <td>0.8417</td>\n      <td>0.8017</td>\n      <td>0.8064</td>\n      <td>0.5627</td>\n      <td>0.5916</td>\n      <td>0.954</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>Random Forest Classifier</td>\n      <td>0.7571</td>\n      <td>0.8833</td>\n      <td>0.7833</td>\n      <td>0.7967</td>\n      <td>0.7719</td>\n      <td>0.5043</td>\n      <td>0.5274</td>\n      <td>0.044</td>\n    </tr>\n    <tr>\n      <th>dt</th>\n      <td>Decision Tree Classifier</td>\n      <td>0.7429</td>\n      <td>0.7500</td>\n      <td>0.7833</td>\n      <td>0.7717</td>\n      <td>0.7529</td>\n      <td>0.4906</td>\n      <td>0.5270</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>ridge</th>\n      <td>Ridge Classifier</td>\n      <td>0.7429</td>\n      <td>0.8250</td>\n      <td>0.7500</td>\n      <td>0.7850</td>\n      <td>0.7495</td>\n      <td>0.4763</td>\n      <td>0.5063</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>gbc</th>\n      <td>Gradient Boosting Classifier</td>\n      <td>0.7429</td>\n      <td>0.8833</td>\n      <td>0.8167</td>\n      <td>0.7567</td>\n      <td>0.7645</td>\n      <td>0.4881</td>\n      <td>0.5215</td>\n      <td>0.024</td>\n    </tr>\n    <tr>\n      <th>xgboost</th>\n      <td>Extreme Gradient Boosting</td>\n      <td>0.7429</td>\n      <td>0.8750</td>\n      <td>0.8417</td>\n      <td>0.7400</td>\n      <td>0.7705</td>\n      <td>0.4786</td>\n      <td>0.5092</td>\n      <td>0.184</td>\n    </tr>\n    <tr>\n      <th>qda</th>\n      <td>Quadratic Discriminant Analysis</td>\n      <td>0.7286</td>\n      <td>0.8083</td>\n      <td>0.7833</td>\n      <td>0.7433</td>\n      <td>0.7301</td>\n      <td>0.4638</td>\n      <td>0.5131</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>lightgbm</th>\n      <td>Light Gradient Boosting Machine</td>\n      <td>0.7286</td>\n      <td>0.8750</td>\n      <td>0.6750</td>\n      <td>0.8100</td>\n      <td>0.7198</td>\n      <td>0.4578</td>\n      <td>0.4814</td>\n      <td>0.059</td>\n    </tr>\n    <tr>\n      <th>catboost</th>\n      <td>CatBoost Classifier</td>\n      <td>0.7286</td>\n      <td>0.8917</td>\n      <td>0.8167</td>\n      <td>0.7467</td>\n      <td>0.7562</td>\n      <td>0.4641</td>\n      <td>0.5021</td>\n      <td>0.722</td>\n    </tr>\n    <tr>\n      <th>ada</th>\n      <td>Ada Boost Classifier</td>\n      <td>0.7143</td>\n      <td>0.7500</td>\n      <td>0.8083</td>\n      <td>0.7167</td>\n      <td>0.7403</td>\n      <td>0.4269</td>\n      <td>0.4620</td>\n      <td>0.022</td>\n    </tr>\n    <tr>\n      <th>lda</th>\n      <td>Linear Discriminant Analysis</td>\n      <td>0.7143</td>\n      <td>0.8000</td>\n      <td>0.7000</td>\n      <td>0.7700</td>\n      <td>0.7183</td>\n      <td>0.4230</td>\n      <td>0.4433</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>et</th>\n      <td>Extra Trees Classifier</td>\n      <td>0.7143</td>\n      <td>0.9083</td>\n      <td>0.7917</td>\n      <td>0.7417</td>\n      <td>0.7312</td>\n      <td>0.4387</td>\n      <td>0.4894</td>\n      <td>0.039</td>\n    </tr>\n    <tr>\n      <th>svm</th>\n      <td>SVM - Linear Kernel</td>\n      <td>0.6000</td>\n      <td>0.7000</td>\n      <td>0.4917</td>\n      <td>0.5083</td>\n      <td>0.4489</td>\n      <td>0.1980</td>\n      <td>0.2235</td>\n      <td>0.008</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>K Neighbors Classifier</td>\n      <td>0.5000</td>\n      <td>0.5250</td>\n      <td>0.5917</td>\n      <td>0.5233</td>\n      <td>0.5302</td>\n      <td>0.0405</td>\n      <td>0.0366</td>\n      <td>0.392</td>\n    </tr>\n    <tr>\n      <th>dummy</th>\n      <td>Dummy Classifier</td>\n      <td>0.4286</td>\n      <td>0.5000</td>\n      <td>0.5000</td>\n      <td>0.2143</td>\n      <td>0.3000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.009</td>\n    </tr>\n  </tbody>\n</table>""}",,,2025-01-17 23:58:09.309031
Churn,"{""progress"": ""Results ready"", ""data"": {""Model"": {""rf"": ""Random Forest Classifier"", ""catboost"": ""CatBoost Classifier"", ""lightgbm"": ""Light Gradient Boosting Machine"", ""xgboost"": ""Extreme Gradient Boosting"", ""et"": ""Extra Trees Classifier"", ""gbc"": ""Gradient Boosting Classifier"", ""dt"": ""Decision Tree Classifier"", ""ada"": ""Ada Boost Classifier"", ""knn"": ""K Neighbors Classifier"", ""ridge"": ""Ridge Classifier"", ""lda"": ""Linear Discriminant Analysis"", ""lr"": ""Logistic Regression"", ""qda"": ""Quadratic Discriminant Analysis"", ""nb"": ""Naive Bayes"", ""svm"": ""SVM - Linear Kernel"", ""dummy"": ""Dummy Classifier""}, ""Accuracy"": {""rf"": 0.8497, ""catboost"": 0.8448, ""lightgbm"": 0.8435, ""xgboost"": 0.8429, ""et"": 0.8384, ""gbc"": 0.827, ""dt"": 0.8178, ""ada"": 0.813, ""knn"": 0.7953, ""ridge"": 0.7943, ""lda"": 0.7939, ""lr"": 0.7929, ""qda"": 0.7894, ""nb"": 0.7645, ""svm"": 0.7333, ""dummy"": 0.5001}, ""AUC"": {""rf"": 0.9284, ""catboost"": 0.9226, ""lightgbm"": 0.9243, ""xgboost"": 0.923, ""et"": 0.9204, ""gbc"": 0.908, ""dt"": 0.8171, ""ada"": 0.8954, ""knn"": 0.8657, ""ridge"": 0.88, ""lda"": 0.88, ""lr"": 0.8807, ""qda"": 0.8726, ""nb"": 0.8504, ""svm"": 0.8136, ""dummy"": 0.5}, ""Recall"": {""rf"": 0.8525, ""catboost"": 0.8635, ""lightgbm"": 0.8563, ""xgboost"": 0.8576, ""et"": 0.8299, ""gbc"": 0.8455, ""dt"": 0.8344, ""ada"": 0.8348, ""knn"": 0.8289, ""ridge"": 0.8129, ""lda"": 0.8119, ""lr"": 0.806, ""qda"": 0.8306, ""nb"": 0.8362, ""svm"": 0.6668, ""dummy"": 0}, ""Prec."": {""rf"": 0.8481, ""catboost"": 0.8326, ""lightgbm"": 0.8351, ""xgboost"": 0.8333, ""et"": 0.8449, ""gbc"": 0.8154, ""dt"": 0.8078, ""ada"": 0.8, ""knn"": 0.7769, ""ridge"": 0.7841, ""lda"": 0.7841, ""lr"": 0.7856, ""qda"": 0.768, ""nb"": 0.732, ""svm"": 0.79, ""dummy"": 0}, ""F1"": {""rf"": 0.85, ""catboost"": 0.8477, ""lightgbm"": 0.8454, ""xgboost"": 0.8452, ""et"": 0.837, ""gbc"": 0.83, ""dt"": 0.8208, ""ada"": 0.8167, ""knn"": 0.8019, ""ridge"": 0.7978, ""lda"": 0.7973, ""lr"": 0.7954, ""qda"": 0.7977, ""nb"": 0.7803, ""svm"": 0.7069, ""dummy"": 0}, ""Kappa"": {""rf"": 0.6994, ""catboost"": 0.6897, ""lightgbm"": 0.6869, ""xgboost"": 0.6859, ""et"": 0.6769, ""gbc"": 0.654, ""dt"": 0.6357, ""ada"": 0.626, ""knn"": 0.5907, ""ridge"": 0.5886, ""lda"": 0.5879, ""lr"": 0.5858, ""qda"": 0.5789, ""nb"": 0.529, ""svm"": 0.4667, ""dummy"": 0}, ""MCC"": {""rf"": 0.6998, ""catboost"": 0.6904, ""lightgbm"": 0.6874, ""xgboost"": 0.6865, ""et"": 0.6775, ""gbc"": 0.6548, ""dt"": 0.6363, ""ada"": 0.627, ""knn"": 0.5922, ""ridge"": 0.5897, ""lda"": 0.589, ""lr"": 0.5865, ""qda"": 0.5815, ""nb"": 0.535, ""svm"": 0.4895, ""dummy"": 0}, ""TT (Sec)"": {""rf"": 0.134, ""catboost"": 1.647, ""lightgbm"": 0.18, ""xgboost"": 0.208, ""et"": 0.118, ""gbc"": 0.127, ""dt"": 0.011, ""ada"": 0.051, ""knn"": 0.344, ""ridge"": 0.009, ""lda"": 0.008, ""lr"": 0.871, ""qda"": 0.009, ""nb"": 0.007, ""svm"": 0.014, ""dummy"": 0.009}}}",,,2025-01-18 00:04:05.163553
